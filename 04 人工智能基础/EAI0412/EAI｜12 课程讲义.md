# EAI｜12 模型决策可解释性与系统透明性设计

课程名称：人工智能基础 

单元主题：AI黑箱问题与可解释系统的构建 

授课年级：初中高年级 / 高一 

计划课时：90分钟

## 课程概括

本节课旨在引导学生认识AI“黑箱”问题，引出可解释性AI（XAI）理念，并掌握基本的模型可视化分析方法。学生将在理解LIME、SHAP等工具原理的基础上，尝试从模型预测中反推出关键特征或错误原因，构建“决策过程可理解”的系统界面雏形，提升AI系统的透明度与信任度。

## 教学目标

### 🎯知识与技能

- 理解“黑箱模型”与可解释AI的基本概念；
- 了解LIME、SHAP等主流可解释性方法的基本原理与作用；
- 能够分析模型输出与输入特征之间的逻辑关系；
- 初步具备构建“可解释界面”的数据可视化能力。

### 🎯过程与方法

- 观察模型“出错”示例，分析其可能的输入误导因素；
- 学生选取一组预测结果进行“错误原因分析”；
- 使用颜色编码、图像遮挡等方式，尝试设计透明反馈系统界面；
- 引导学生提出改善“用户信任AI”的界面设计建议。

### 🎯情感态度价值观

- 培养学生对“结果正确 ≠ 模型可靠”的深度认知；
- 引导理性对待AI系统的判断与责任归属；
- 强化透明、可控、可信赖的AI系统建设价值观。

## 重点难点

| 教学重点               | 教学难点                           |
| ---------------------- | ---------------------------------- |
| 可解释AI概念与方法介绍 | 将模型行为“转译”为人类可理解逻辑   |
| 错误分析与界面反馈设计 | 用界面语言表达模型决策依据与偏差点 |

## 教学准备

| 软件               | 硬件             | 扩展                              |
| ------------------ | ---------------- | --------------------------------- |
| 图像标注工具 / PPT | 学生电脑、摄像头 | LIME可视化样例图 / 错误图像素材集 |

## 教学过程

| 环节       | 主要内容                                                     | 预计时长 | 素材附件               |
| ---------- | ------------------------------------------------------------ | -------- | ---------------------- |
| 导入       | 播放“模型预测错误”示例，引导学生讨论“它错在哪里？”           | 10分钟   | 错误预测案例视频.mp4   |
| 知识讲解   | 讲解可解释AI的背景、原理、LIME与SHAP的思想差异与代表性应用   | 20分钟   | 课件PPT_12.pdf         |
| 错误分析   | 小组挑选一个训练数据模型的错判样本，手动标注可能影响因素，分析失误成因 | 25分钟   | 错误样本分析表格.xlsx  |
| 可视化设计 | 学生尝试使用色块、热力图等方式，表达“系统是如何判断的”界面反馈 | 20分钟   | 可解释界面设计模板.pdf |
| 分享讨论   | 各组展示可视化结果并讲解其背后逻辑，教师点评“透明度”与“表达力”的融合能力 | 10分钟   | 展示表 / 打分卡        |

## 课程总结

| 内容     | 主要内容                                                     | 预计时长 | 素材附件        |
| -------- | ------------------------------------------------------------ | -------- | --------------- |
| 知识回顾 | 黑箱模型、可解释方法、错误原因分析流程                       | 5分钟    | 总结PPT_12.pdf  |
| 学生反思 | “你会因为AI解释得‘清楚’而更愿意相信它吗？为什么？”           | 5分钟    | 反思卡片12.docx |
| 作业布置 | 对自己的模型挑选两个预测错误的样本，写出原因推测与可视化表达建议 | 2分钟    | -               |